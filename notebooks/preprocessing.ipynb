{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Script for RECS 2020 Dataset\n",
    "# ========================================\n",
    "# This script loads raw RECS 2020 CSV files, merges them on 'STATE', handles missing values,\n",
    "# removes outliers, encodes categorical variables, scale features and saves the processed dataset.\n",
    "#\n",
    "# Inputs:\n",
    "# - Raw CSV files in data/raw/\n",
    "# Outputs:\n",
    "# - Processed unscaled dataset in data/processed/merged_cleaned.csv for fuzzy logic and app ranges.\n",
    "# - Processed scaled dataset in data/processed/merged_cleaned_scaled.csv for Decision Tree training.\n",
    "#\n",
    "# Dependencies: pandas, numpy, scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c0a68-7bb8-42c8-8c02-296fbe4b11c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Setup paths\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "RAW_DIR = os.path.join(DATA_DIR, \"raw\")\n",
    "PROCESSED_DIR = os.path.join(DATA_DIR, \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all raw CSV files\n",
    "consumption = pd.read_csv(os.path.join(RAW_DIR, \"recs_annual_household_energy_consumption_and_expenditure.csv\"))\n",
    "housing = pd.read_csv(os.path.join(RAW_DIR, \"recs_type_of_housing.csv\"))\n",
    "income = pd.read_csv(os.path.join(RAW_DIR, \"recs_income.csv\"))\n",
    "geographic = pd.read_csv(os.path.join(RAW_DIR, \"recs_geographic_characteristics.csv\"))\n",
    "year_construction = pd.read_csv(os.path.join(RAW_DIR, \"recs_year_of_construction.csv\"))\n",
    "ac_equipment = pd.read_csv(os.path.join(RAW_DIR, \"recs_use_of_ac_and_age_of_ac_equipment.csv\"))\n",
    "space_heater = pd.read_csv(os.path.join(RAW_DIR, \"recs_use_of_space_heaters_and_age_of_space_heating_equipment.csv\"))\n",
    "water_heater = pd.read_csv(os.path.join(RAW_DIR, \"recs_age_of_water_heating_equipment.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18791bde-0941-4b9a-a400-53f919510177",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(consumption.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0d2d2f-e261-418d-a9ac-4fb26a9e274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53bcf8-7124-43e8-83c7-d0b25ac699c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(income.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eef8ec-d8fa-434c-a6c0-94a364571ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(geographic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b1bdc-7c20-4591-b220-c0e78aefb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(year_construction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df1a1b-6f7b-47aa-8542-63a228d47e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ac_equipment.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc98b41-b123-4a06-bfa8-148813cd6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(space_heater.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b0b71-e764-4a4b-9207-bcf24a8ec40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(water_heater.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5af15-f052-4606-a413-902e26dd5ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate 'Total_households' columns (keep consumption's)\n",
    "for df in [housing, income, year_construction, ac_equipment, space_heater, water_heater]:\n",
    "    if 'Total_households' in df.columns:\n",
    "        df.drop(columns=['Total_households'], inplace=True)\n",
    "\n",
    "# Merge datasets on 'STATE'\n",
    "merged = consumption.merge(housing, on='STATE', how='inner')\n",
    "merged = merged.merge(income, on='STATE', how='inner')\n",
    "merged = merged.merge(geographic, on='STATE', how='inner')\n",
    "merged = merged.merge(year_construction, on='STATE', how='inner')\n",
    "merged = merged.merge(ac_equipment, on='STATE', how='inner')\n",
    "merged = merged.merge(space_heater, on='STATE', how='inner')\n",
    "merged = merged.merge(water_heater, on='STATE', how='inner')\n",
    "\n",
    "# Inspect the merged dataset\n",
    "print(\"Shape:\", merged.shape)\n",
    "print(merged.head())\n",
    "print(\"\\nColumns:\\n\", merged.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1133dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values with median for numeric columns\n",
    "numeric_columns = merged.select_dtypes(include=[np.number]).columns\n",
    "merged[numeric_columns] = merged[numeric_columns].fillna(merged[numeric_columns].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using IQR method\n",
    "for col in ['ENERGY_CONSUMPTION_PER_SQFT', 'Pct_INCOME_MORE_THAN_150K', 'Pct_MAIN_HEAT_AGE_OLDER_THAN_20']:\n",
    "    Q1 = merged[col].quantile(0.25)\n",
    "    Q3 = merged[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    merged = merged[(merged[col] >= lower_bound) & (merged[col] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure CLIMATE_Cold exists\n",
    "if 'CLIMATE_Cold' not in merged.columns:\n",
    "    print(\"Warning: CLIMATE_Cold not found. Creating dummy column with value 0.\")\n",
    "    merged['CLIMATE_Cold'] = 0\n",
    "else:\n",
    "    # Encode CLIMATE_Cold as binary (0/1)\n",
    "    merged['CLIMATE_Cold'] = merged['CLIMATE_Cold'].apply(lambda x: 1 if x in [1, 'Yes', True] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92dc838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode climate variables (ensure binary)\n",
    "climate_columns = ['CLIMATE_Hot-Humid', 'CLIMATE_Mixed-Humid', 'CLIMATE_Very-Cold']\n",
    "for col in climate_columns:\n",
    "    if col in merged.columns:\n",
    "        merged[col] = merged[col].apply(lambda x: 1 if x in [1, 'Yes', True] else 0)\n",
    "    else:\n",
    "        print(f\"Warning: {col} not found. Creating dummy column with value 0.\")\n",
    "        merged[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a84db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select required features\n",
    "selected_features = [\n",
    "    'STATE', 'ENERGY_CONSUMPTION_PER_SQFT', 'Pct_INCOME_MORE_THAN_150K',\n",
    "    'Pct_HOUSING_SINGLE_FAMILY_HOME_DETACHED', 'Pct_HOUSING_APT_MORE_THAN_5_UNITS',\n",
    "    'CLIMATE_Cold', 'CLIMATE_Hot-Humid', 'CLIMATE_Mixed-Humid', 'CLIMATE_Very-Cold',\n",
    "    'Pct_BUILT_BEFORE_1950', 'Pct_MAIN_AC_AGE_OLDER_THAN_20',\n",
    "    'Pct_MAIN_HEAT_AGE_OLDER_THAN_20', 'Pct_MAIN_WATER_HEAT_OLDER_THAN_20'\n",
    "]\n",
    "available_features = [col for col in selected_features if col in merged.columns]\n",
    "merged = merged[available_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4024a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed dataset\n",
    "output_path = os.path.join(PROCESSED_DIR, \"merged_cleaned.csv\")\n",
    "merged.to_csv(output_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Processed unscaled dataset saved to {output_path}\")\n",
    "print(\"Shape:\", merged.shape)\n",
    "print(\"Columns:\", merged.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale continuous features\n",
    "continuous_features = [\n",
    "    'ENERGY_CONSUMPTION_PER_SQFT', 'Pct_INCOME_MORE_THAN_150K',\n",
    "    'Pct_HOUSING_SINGLE_FAMILY_HOME_DETACHED', 'Pct_HOUSING_APT_MORE_THAN_5_UNITS',\n",
    "    'Pct_BUILT_BEFORE_1950', 'Pct_MAIN_AC_AGE_OLDER_THAN_20',\n",
    "    'Pct_MAIN_HEAT_AGE_OLDER_THAN_20', 'Pct_MAIN_WATER_HEAT_OLDER_THAN_20'\n",
    "]\n",
    "continuous_features = [f for f in continuous_features if f in merged.columns]\n",
    "scaler = StandardScaler()\n",
    "scaled_data = merged.copy()\n",
    "scaled_data[continuous_features] = scaler.fit_transform(merged[continuous_features])\n",
    "\n",
    "# Save scaled dataset\n",
    "scaled_output_path = os.path.join(PROCESSED_DIR, 'merged_cleaned_scaled.csv')\n",
    "scaled_data.to_csv(scaled_output_path, index=False)\n",
    "print(f'Saved scaled dataset: {scaled_output_path}')\n",
    "\n",
    "# Print summary\n",
    "print('Shape:', merged.shape)\n",
    "print('Columns:', merged.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
